{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import *\n",
    "\n",
    "data = pd.read_csv('classification.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 34, 59, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP,TN,FP,FN = 0,0,0,0\n",
    "\n",
    "for row in data:\n",
    "    if row[0] == 1 and row[1] == 1:\n",
    "        TP += 1\n",
    "    elif row[0] == 0 and row[1] == 0:\n",
    "        TN += 1\n",
    "    elif row[0] == 0 and row[1] == 1:\n",
    "        FP += 1\n",
    "    else:\n",
    "        FN += 1\n",
    "\n",
    "TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.54, 0.56, 0.42, 0.48)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = round(accuracy_score(data[:,0], data[:,1]),2)\n",
    "precision = round(precision_score(data[:,0], data[:,1]),2)\n",
    "recall = round(recall_score(data[:,0], data[:,1]),2)\n",
    "f_score = round(f1_score(data[:,0], data[:,1]),2)\n",
    "\n",
    "accuracy, precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.719187675070028, 0.7086834733893557, 0.6351540616246498, 0.6919267707082833)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('scores.csv').values\n",
    "true_values = data[:,0]\n",
    "logreg_pred = data[:,1]\n",
    "svm_pred = data[:,2]\n",
    "knn_pred = data[:,3]\n",
    "tree_pred = data[:,4]\n",
    "\n",
    "logreg_roc = roc_auc_score(true_values, logreg_pred)\n",
    "svm_roc = roc_auc_score(true_values, svm_pred)\n",
    "knn_roc = roc_auc_score(true_values, knn_pred)\n",
    "tree_roc = roc_auc_score(true_values, tree_pred)\n",
    "\n",
    "logreg_roc, svm_roc, knn_roc, tree_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_precision, logreg_recall, _ = precision_recall_curve(true_values, logreg_pred)\n",
    "svm_precision, svm_recall, _ = precision_recall_curve(true_values, svm_pred)\n",
    "knn_precision, knn_recall, _ = precision_recall_curve(true_values, knn_pred)\n",
    "tree_precision, tree_recall, _ = precision_recall_curve(true_values, tree_pred)\n",
    "\n",
    "logreg_pr = [x[0] for x in zip(logreg_precision, logreg_recall) if x[1] >= 0.7]\n",
    "svm_pr = [x[0] for x in zip(svm_precision, svm_recall) if x[1] >= 0.7]\n",
    "knn_pr = [x[0] for x in zip(knn_precision, knn_recall) if x[1] >= 0.7]\n",
    "tree_pr = [x[0] for x in zip(tree_precision, tree_recall) if x[1] >= 0.7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6302521008403361,\n",
       " 0.6228070175438597,\n",
       " 0.6065573770491803,\n",
       " 0.6517857142857143)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(logreg_pr), max(svm_pr), max(knn_pr), max(tree_pr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
